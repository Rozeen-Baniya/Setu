# -*- coding: utf-8 -*-
"""model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13P148R86xDUUriP5H3fmzHvVQDBOWZFS
"""

# If running outside Colab/Jupyter, install efficientnet_pytorch using pip in your terminal:
# pip install efficientnet_pytorch

import os
import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
from efficientnet_pytorch import EfficientNet
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt

# Paths
data_dir = '/content/drive/MyDrive/static-word-based-NSL/thesis/all'
save_path = '/content/drive/MyDrive/static-word-based-NSL/thesis/all/sign_language_model.pth'

# Parameters
batch_size = 32
img_size = 224
num_classes = 4
num_epochs = 10
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Transforms
transform = transforms.Compose([
    transforms.Resize((img_size, img_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Dataset
dataset = datasets.ImageFolder(root=data_dir, transform=transform)

# Optional: split off a validation set
train_size = int(0.9 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size)

model = EfficientNet.from_pretrained('efficientnet-b0')
model._fc = nn.Linear(model._fc.in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()

    epoch_loss = running_loss / len(train_dataset)
    epoch_acc = correct / len(train_dataset)
    print(f"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f}")

torch.save(model.state_dict(), save_path)
print(f"Model saved to: {save_path}")

# To load the model again
model = EfficientNet.from_name('efficientnet-b0')
model._fc = nn.Linear(model._fc.in_features, num_classes)
model.load_state_dict(torch.load(save_path))
model = model.to(device)
model.eval()

# If running outside Colab/Jupyter, install these packages using pip in your terminal:
# pip install efficientnet_pytorch opencv-python-headless

from efficientnet_pytorch import EfficientNet
import torch
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = EfficientNet.from_name('efficientnet-b0')
model._fc = nn.Linear(model._fc.in_features, 4)  # 4 classes
model.load_state_dict(torch.load('/content/drive/MyDrive/static-word-based-NSL/thesis/all/sign_language_model.pth'))
model = model.to(device)
model.eval()

from IPython.display import display, Javascript
from google.colab.output import eval_js
import base64
import cv2
import numpy as np

def take_photo_auto(filename='photo.jpg', quality=0.8, countdown=3):
    js = Javascript(f'''
        async function takePhoto(quality) {{
          const div = document.createElement('div');
          const countdownEl = document.createElement('h2');
          const video = document.createElement('video');
          video.style.display = 'block';
          countdownEl.textContent = 'Get ready...';
          div.appendChild(countdownEl);
          div.appendChild(video);
          document.body.appendChild(div);

          const stream = await navigator.mediaDevices.getUserMedia({{video: true}});
          video.srcObject = stream;
          await video.play();

          // Resize iframe to fit
          google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

          // Countdown
          for (let i = {countdown}; i > 0; i--) {{
            countdownEl.textContent = 'Capturing in ' + i + '...';
            await new Promise(resolve => setTimeout(resolve, 1000));
          }}

          countdownEl.textContent = 'üì∏ Capturing...';

          // Capture the photo
          const canvas = document.createElement('canvas');
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          canvas.getContext('2d').drawImage(video, 0, 0);
          stream.getTracks().forEach(track => track.stop());
          div.remove();

          return canvas.toDataURL('image/jpeg', quality);
        }}
    ''')

    display(js)
    data = eval_js("takePhoto({})".format(quality))
    binary = base64.b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

img_path = take_photo_auto(countdown=3)  # 3-second countdown

from PIL import Image as PILImage
import torchvision.transforms as transforms

# Transform and predict
image = PILImage.open(img_path).convert('RGB')
input_tensor = transform(image).unsqueeze(0).to(device)

# Get class names from the dataset
class_names = dataset.classes

with torch.no_grad():
    outputs = model(input_tensor)
    _, predicted = torch.max(outputs, 1)
    pred_class = class_names[predicted.item()]
    print(f"üñê Predicted Class: {pred_class}")

